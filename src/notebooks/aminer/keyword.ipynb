{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# キーワード抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "import re\n",
    "import datetime as dt\n",
    "import time\n",
    "import japanize_matplotlib\n",
    "year_pattern = r'([1-2][0-9]{3})'\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = \"../../../data/\"\n",
    "START_YEAR = 2000\n",
    "END_YEAR = 2015\n",
    "YEAR_STD = END_YEAR - START_YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(filename):\n",
    "    with open(DATAPATH + filename, encoding=\"utf-8\", mode='r') as f:\n",
    "        for line in f:\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## キーワードの抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83ab65157e346e4aebe10e0dca1ae7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "キーワードの数:6272597, キーワードのない論文数:1171591,\n",
      " 期間が妥当である論文数2324357, 期間外の論文数1089509\n",
      "CPU times: user 2min 2s, sys: 13.7 s, total: 2min 16s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 2min30s needed\n",
    "keywords = {}\n",
    "count, count2, count3 = 0, 0, 0\n",
    "\n",
    "metadata = get_metadata(\"dblpv13.txt\")\n",
    "for paper in tqdm(metadata):\n",
    "    data = json.loads(paper)\n",
    "    try:\n",
    "        k = data.get('keywords')\n",
    "        y = data.get('year')\n",
    "        if len(k) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            if y >= START_YEAR and  END_YEAR >= y :\n",
    "                for i in k:\n",
    "                    i = i.lower().strip()\n",
    "                    if i == \"\":\n",
    "                        pass\n",
    "                    elif i not in keywords:\n",
    "                        keywords[i] = 1\n",
    "                    else:\n",
    "                        keywords[i] = keywords[i] + 1\n",
    "                count2 += 1\n",
    "            else:\n",
    "                count3 += 1\n",
    "    except Exception as e:\n",
    "        # keywordがないものも存在\n",
    "        count += 1\n",
    "        pass\n",
    "print(\"キーワードの数:{}, キーワードのない論文数:{},\\n 期間が妥当である論文数{}, 期間外の論文数{}\".format(len(keywords), count, count2, count3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6b82371e484290bfa01a31fe39de7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6272597 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出現数が1000以上のキーワード数:2533\n",
      "CPU times: user 3.44 s, sys: 88 ms, total: 3.53 s\n",
      "Wall time: 3.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "important_keywords = []\n",
    "M = 1000\n",
    "for keyword in tqdm(keywords):\n",
    "    # keyword の出現回数が、Mを超えるとき\n",
    "    appear_count = keywords[keyword]\n",
    "    if appear_count >= M:\n",
    "        important_keywords.append(keyword)\n",
    "print(\"出現数が\" + str(M) + \"以上のキーワード数:{}\".format(len(important_keywords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_keywords.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important_keywords = np.array(important_keywords)\n",
    "# np.save(DATAPATH + \"DBLP/keywords.npy\", important_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATAPATH + \"DBLP/keywords.txt\", mode=\"a\") as f:\n",
    "    for i in important_keywords:\n",
    "        f.write(i + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2533"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(important_keywords)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6efa27fe81c14238ae2d5738124b190f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2533 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "達成率: 0%, 経過時間: 0.029930830001831055\n",
      "達成率: 10%, 経過時間: 55.98400354385376\n",
      "達成率: 20%, 経過時間: 84.11372375488281\n",
      "CPU times: user 1min 28s, sys: 588 ms, total: 1min 28s\n",
      "Wall time: 1min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 平均0.260 の類似度\n",
    "# 8minほどかかる\n",
    "similar_pair = []\n",
    "start_time = time.time()\n",
    "for i in tqdm(range(N)):\n",
    "    if i % 1000 == 0:\n",
    "        end_time = time.time()\n",
    "        print(\"達成率: {}, 経過時間: {}\".format(str(i // 100) + \"%\", end_time-start_time))\n",
    "    for j in range(i+1,N):\n",
    "        a = important_keywords[i]\n",
    "        b = important_keywords[j]\n",
    "        r = difflib.SequenceMatcher(isjunk=None, a=a, b=b, autojunk=True).ratio()\n",
    "        if r > 0.9:\n",
    "            similar_pair.append([keywords[a],keywords[b],a,b,round(r,3)])\n",
    "len(similar_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, sim_pair in enumerate(similar_pair):\n",
    "    if sim_pair[0] >= sim_pair[1]:\n",
    "        continue\n",
    "    else:\n",
    "        similar_pair[num][0], similar_pair[num][1] = similar_pair[num][1], similar_pair[num][0]\n",
    "        similar_pair[num][2], similar_pair[num][3] = similar_pair[num][3], similar_pair[num][2]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_pair = sorted(similar_pair, key=lambda x:(x[2], x[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (array([144]),) ['2831' '1046' '3g mobile communication' 'mobile communications' '0.909']\n",
      "22 (array([21]),) ['1515' '1417' 'case-based reasoning' 'case based reasoning' '0.95']\n",
      "92 (array([91]),) ['18051' '1471' 'genetic algorithms' 'generic algorithm' '0.914']\n",
      "96 (array([98]),) ['2218' '1436' 'graphic user interface' 'graphical user interface' '0.957']\n",
      "152 (array([156]),) ['6596' '3035' 'multi agent system' 'multi-agent system' '0.944']\n",
      "153 (array([156]),) ['6596' '5862' 'multi agent system' 'multi-agent systems' '0.919']\n",
      "154 (array([156]),) ['6596' '1283' 'multi agent system' 'multiagent system' '0.971']\n",
      "155 (array([156]),) ['6596' '2976' 'multi agent system' 'multiagent systems' '0.944']\n",
      "161 (array([170]),) ['1924' '1535' 'multi objective optimization'\n",
      " 'multi-objective optimization' '0.964']\n",
      "163 (array([152, 157, 165]),) ['3035' '1283' 'multi-agent system' 'multiagent system' '0.971']\n",
      "164 (array([152, 157, 165]),) ['3035' '2976' 'multi-agent system' 'multiagent systems' '0.944']\n",
      "165 (array([153, 158]),) ['5862' '3035' 'multi-agent systems' 'multi-agent system' '0.973']\n",
      "166 (array([153, 158]),) ['5862' '1283' 'multi-agent systems' 'multiagent system' '0.944']\n",
      "167 (array([153, 158]),) ['5862' '2976' 'multi-agent systems' 'multiagent systems' '0.973']\n",
      "168 (array([155, 160, 164, 167]),) ['2976' '1283' 'multiagent systems' 'multiagent system' '0.971']\n",
      "178 (array([129]),) ['6168' '4285' 'nonlinear systems' 'nonlinear system' '0.97']\n",
      "197 (array([196]),) ['4992' '1277' 'real-time systems' 'real-time system' '0.97']\n"
     ]
    }
   ],
   "source": [
    "similar_pair = np.array(similar_pair)\n",
    "for num, sim_pair in enumerate(similar_pair):\n",
    "    if sim_pair[2] in similar_pair[:,3]:\n",
    "        print(num, np.where(similar_pair[:,3]==sim_pair[2]), sim_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATAPATH + \"DBLP/sim_keywords.txt\", mode=\"a\") as f:\n",
    "    for i in similar_pair:\n",
    "        f.write(i[2] + \",\" + i[3] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 現在は手動でやっているが、類義語同士の重複などを消去する必要がある\n",
    "あ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235, ['3g mobile communication', 'mobile communications'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(DATAPATH + \"DBLP/sim_keywords.txt\") as f:\n",
    "    sim_keywords = list(map(lambda x: x.replace(\"\\n\", \"\"), f.readlines()))\n",
    "    sim_keywords = list(map(lambda x: list(x.split(\",\")), sim_keywords))\n",
    "len(sim_keywords), sim_keywords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3g mobile communication': 'mobile communications',\n",
       " 'ad hoc networks': 'ad hoc network',\n",
       " 'adaptive filters': 'adaptive filter',\n",
       " 'adaptive systems': 'adaptive system',\n",
       " 'agents': 'agent',\n",
       " 'algorithms': 'algorithm',\n",
       " 'analytical model': 'analytical models',\n",
       " 'antenna arrays': 'antenna array',\n",
       " 'approximation algorithms': 'approximation algorithm',\n",
       " 'artificial intelligence': 'artificial intelligent',\n",
       " 'artificial neural networks': 'artificial neural network',\n",
       " 'association rule': 'association rules',\n",
       " 'authorisation': 'authorization',\n",
       " 'backpropagation': 'back propagation',\n",
       " 'base station': 'base stations',\n",
       " 'bayesian methods': 'bayesian method',\n",
       " 'bayesian network': 'bayesian networks',\n",
       " 'biomedical imaging': 'medical imaging',\n",
       " 'boolean functions': 'boolean function',\n",
       " 'brain computer interface': 'brain computer interfaces',\n",
       " 'case base reasoning': 'case based reasoning',\n",
       " 'case-based reasoning': 'case based reasoning',\n",
       " 'cellular automata': 'cellular automaton',\n",
       " 'cellular network': 'cellular networks',\n",
       " 'closed loop systems': 'closed-loop system',\n",
       " 'clustering algorithms': 'clustering algorithm',\n",
       " 'codes': 'codecs',\n",
       " 'cognitive radio network': 'cognitive radio networks',\n",
       " 'communication channels': 'telecommunication channels',\n",
       " 'communication networks': 'communication network',\n",
       " 'communication system': 'communication systems',\n",
       " 'communications technology': 'communication technology',\n",
       " 'complex network': 'complex networks',\n",
       " 'complex system': 'complex systems',\n",
       " 'compressed sensing': 'compressive sensing',\n",
       " 'computational modeling': 'computational model',\n",
       " 'computed tomography': 'computerised tomography',\n",
       " 'computer graphics': 'computer graphic',\n",
       " 'computer networks': 'computer network',\n",
       " 'constraint optimization': 'constrained optimization',\n",
       " 'contextual information': 'context information',\n",
       " 'control systems': 'control system',\n",
       " 'convolution': 'deconvolution',\n",
       " 'convolutional codes': 'convolutional code',\n",
       " 'correlation': 'decorrelation',\n",
       " 'cryptographic protocols': 'cryptographic protocol',\n",
       " 'data models': 'data model',\n",
       " 'data stream': 'data streams',\n",
       " 'data structure': 'data structures',\n",
       " 'data visualisation': 'data visualization',\n",
       " 'data warehouse': 'data warehouses',\n",
       " 'database management systems': 'database management system',\n",
       " 'database system': 'database systems',\n",
       " 'databases': 'database',\n",
       " 'decision support systems': 'decision support system',\n",
       " 'decision tree': 'decision trees',\n",
       " 'delays': 'delay',\n",
       " 'design pattern': 'design patterns',\n",
       " 'differential equations': 'differential equation',\n",
       " 'digital image': 'digital images',\n",
       " 'digital signatures': 'digital signature',\n",
       " 'digital watermarking': 'digital watermark',\n",
       " 'directed graph': 'directed graphs',\n",
       " 'discrete cosine transform': 'discrete cosine transforms',\n",
       " 'discrete fourier transform': 'discrete fourier transforms',\n",
       " 'discrete wavelet transform': 'discrete wavelet transforms',\n",
       " 'distributed algorithms': 'distributed algorithm',\n",
       " 'distributed databases': 'distributed database',\n",
       " 'distributed system': 'distributed systems',\n",
       " 'embedded systems': 'embedded system',\n",
       " 'energy efficiency': 'energy efficient',\n",
       " 'error correction codes': 'error correction code',\n",
       " 'evolutionary algorithm': 'evolutionary algorithms',\n",
       " 'evolutionary computation': 'evolutionary computing',\n",
       " 'expectation-maximisation algorithm': 'expectation maximization algorithm',\n",
       " 'expert system': 'expert systems',\n",
       " 'fading channels': 'fading channel',\n",
       " 'fast fourier transforms': 'fast fourier transform',\n",
       " 'field programmable gate arrays': 'field programmable gate array',\n",
       " 'finite element method': 'finite element methods',\n",
       " 'finite state machines': 'finite state machine',\n",
       " 'fir filters': 'fir filter',\n",
       " 'formal language': 'formal languages',\n",
       " 'formal method': 'formal methods',\n",
       " 'fourier transforms': 'fourier transform',\n",
       " 'frequency domain analysis': 'frequency-domain analysis',\n",
       " 'fuzzy set': 'fuzzy sets',\n",
       " 'fuzzy systems': 'fuzzy system',\n",
       " 'gaussian processes': 'gaussian process',\n",
       " 'genetic algorithm': 'generic algorithm',\n",
       " 'genetic algorithms': 'generic algorithm',\n",
       " 'geographic information systems': 'geographic information system',\n",
       " 'government': 'e government',\n",
       " 'graph': 'graphs',\n",
       " 'graphic user interface': 'graphical user interface',\n",
       " 'graphical model': 'graphical models',\n",
       " 'graphical user interfaces': 'graphical user interface',\n",
       " 'greedy algorithms': 'greedy algorithm',\n",
       " 'haptic interfaces': 'haptic interface',\n",
       " 'health care': 'healthcare',\n",
       " 'heterogeneous network': 'heterogeneous networks',\n",
       " 'heuristic algorithm': 'heuristic algorithms',\n",
       " 'hidden markov models': 'hidden markov model',\n",
       " 'human computer interaction': 'human-computer interaction',\n",
       " 'human robot interaction': 'human-robot interaction',\n",
       " 'humanoid robots': 'humanoid robot',\n",
       " 'hybrid system': 'hybrid systems',\n",
       " 'image registration': 'image restoration',\n",
       " 'image sequences': 'image sequence',\n",
       " 'important role': 'important problem',\n",
       " 'information system': 'information systems',\n",
       " 'integrated circuit': 'integrated circuits',\n",
       " 'integrated circuit design': 'integrated circuit testing',\n",
       " 'intelligent agent': 'intelligent agents',\n",
       " 'interaction': 'integration',\n",
       " 'inverse problems': 'inverse problem',\n",
       " 'investment': 'investments',\n",
       " 'iterative methods': 'iterative method',\n",
       " 'kalman filters': 'kalman filter',\n",
       " 'knowledge based systems': 'knowledge based system',\n",
       " 'learning artificial intelligence': 'learning (artificial intelligence',\n",
       " 'least squares approximations': 'least squares approximation',\n",
       " 'linear codes': 'linear code',\n",
       " 'linear matrix inequality': 'linear matrix inequalities',\n",
       " 'linear programming': 'nonlinear programming',\n",
       " 'linear systems': 'linear system',\n",
       " 'location based service': 'location based services',\n",
       " 'logic gates': 'logic gate',\n",
       " 'low power electronics': 'low-power electronics',\n",
       " 'magnetic resonance imaging': 'magnetic resonance image',\n",
       " 'markov chain': 'markov chains',\n",
       " 'markov processes': 'markov process',\n",
       " 'matched filters': 'matched filter',\n",
       " 'mathematical model': 'mathematical models',\n",
       " 'maximum likelihood estimation': 'maximum likelihood estimate',\n",
       " 'mesh network': 'mesh networks',\n",
       " 'meta data': 'metadata',\n",
       " 'minimisation': 'minimization',\n",
       " 'mobile ad hoc networks': 'mobile ad hoc network',\n",
       " 'mobile agent': 'mobile agents',\n",
       " 'mobile communication': 'mobile communications',\n",
       " 'mobile device': 'mobile devices',\n",
       " 'mobile robots': 'mobile robot',\n",
       " 'modeling': 'modelling',\n",
       " 'modulation': 'demodulation',\n",
       " 'monte carlo methods': 'monte carlo method',\n",
       " 'monte carlo simulation': 'monte carlo simulations',\n",
       " 'multi agent system': 'multiagent system',\n",
       " 'multi agent systems': 'multiagent system',\n",
       " 'multi objective optimization': 'multi-objective optimization',\n",
       " 'multi threading': 'multi-threading',\n",
       " 'multi-agent system': 'multiagent system',\n",
       " 'multi-agent systems': 'multiagent system',\n",
       " 'multiagent systems': 'multiagent system',\n",
       " 'multilayer perceptron': 'multilayer perceptrons',\n",
       " 'multiobjective optimization': 'multi-objective optimization',\n",
       " 'natural language': 'natural languages',\n",
       " 'nearest neighbor': 'k nearest neighbor',\n",
       " 'networks': 'network',\n",
       " 'neural network': 'neural networks',\n",
       " 'next generation networking': 'next generation networks',\n",
       " 'nonlinear equations': 'linear equations',\n",
       " 'nonlinear systems': 'nonlinear system',\n",
       " 'np hard problem': 'np-hard problem',\n",
       " 'object oriented programming': 'object-oriented programming',\n",
       " 'operating system': 'operating systems',\n",
       " 'operations research': 'operational research',\n",
       " 'optimization': 'optimisation',\n",
       " 'parallel algorithms': 'parallel algorithm',\n",
       " 'partial differential equations': 'partial differential equation',\n",
       " 'particle filter': 'particle filters',\n",
       " 'particle swarm optimization': 'particle swarm optimisation',\n",
       " 'petri nets': 'petri net',\n",
       " 'power amplifier': 'power amplifiers',\n",
       " 'power system': 'power systems',\n",
       " 'programming language': 'programming languages',\n",
       " 'protocols': 'protocol',\n",
       " 'radiofrequency identification': 'radio frequency identification',\n",
       " 'random variables': 'random variable',\n",
       " 'real time systems': 'real-time system',\n",
       " 'real-time systems': 'real-time system',\n",
       " 'receivers': 'receiver',\n",
       " 'recommender system': 'recommender systems',\n",
       " 'recurrent neural network': 'recurrent neural networks',\n",
       " 'relational database': 'relational databases',\n",
       " 'requirements engineering': 'requirement engineering',\n",
       " 'robots': 'robot',\n",
       " 'rough set': 'rough sets',\n",
       " 'routing protocols': 'routing protocol',\n",
       " 'search engine': 'search engines',\n",
       " 'semi supervised learning': 'semi-supervised learning',\n",
       " 'sensor network': 'sensor networks',\n",
       " 'sensors': 'sensor',\n",
       " 'service oriented architecture': 'service-oriented architecture',\n",
       " 'signal to noise ratio': 'signal-to-noise ratio',\n",
       " 'smart card': 'smart cards',\n",
       " 'smart grid': 'smart grids',\n",
       " 'social network': 'social networking',\n",
       " 'social sciences': 'social science',\n",
       " 'software agents': 'software agent',\n",
       " 'software systems': 'software system',\n",
       " 'solid modeling': 'solid modelling',\n",
       " 'space-time codes': 'space time code',\n",
       " 'spine': 'spline',\n",
       " 'standardization': 'standardisation',\n",
       " 'statistical test': 'statistical testing',\n",
       " 'stochastic processes': 'stochastic process',\n",
       " 'supply chain': 'supply chains',\n",
       " 'support vector machines': 'support vector machine',\n",
       " 'synchronization': 'synchronisation',\n",
       " 'system on chip': 'system on a chip',\n",
       " 'systems biology': 'system biology',\n",
       " 'three dimensional': 'three dimensions',\n",
       " 'time frequency analysis': 'time-frequency analysis',\n",
       " 'transfer functions': 'transfer function',\n",
       " 'transmitters': 'transmitter',\n",
       " 'transport protocols': 'transport protocol',\n",
       " 'turbo codes': 'turbo code',\n",
       " 'unsupervised learning': 'supervised learning',\n",
       " 'user interfaces': 'user interface',\n",
       " 'vehicular ad hoc networks': 'vehicular ad hoc network',\n",
       " 'video sequence': 'video sequences',\n",
       " 'virtual machines': 'virtual machine',\n",
       " 'virtual worlds': 'virtual world',\n",
       " 'virtualization': 'virtualisation',\n",
       " 'wavelet transforms': 'wavelet transform',\n",
       " 'web application': 'web applications',\n",
       " 'web pages': 'web page',\n",
       " 'web service': 'web services',\n",
       " 'web sites': 'web site',\n",
       " 'wireless channels': 'wireless channel',\n",
       " 'wireless communication': 'wireless communications',\n",
       " 'wireless mesh network': 'wireless mesh networks',\n",
       " 'wireless network': 'wireless networks',\n",
       " 'wireless sensor networks': 'wireless sensor network'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_keywords_dic = {}\n",
    "for i in sim_keywords:\n",
    "    sim_keywords_dic[i[0]] = i[1]\n",
    "sim_keywords_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_similar_words( keyword_list: list, sim_keywords_dict: dict):\n",
    "    ans = []\n",
    "    if len(keyword_list) == 0:\n",
    "        return keyword_list\n",
    "    else:\n",
    "        for keyword_ in keyword_list:\n",
    "            keyword_ = keyword_.lower().strip()\n",
    "            if keyword_ in sim_keywords_dict:\n",
    "                ans.append(sim_keywords_dict[keyword_])\n",
    "            else:\n",
    "                ans.append(keyword_)\n",
    "    return list(set(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41fa511b3974bfeacba40d524b8769b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 39s, sys: 56.6 s, total: 6min 36s\n",
      "Wall time: 6min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metadata = get_metadata(\"dblpv13.txt\")\n",
    "for paper in tqdm(metadata):\n",
    "# for paper in metadata:\n",
    "    data = json.loads(paper)\n",
    "    try:\n",
    "        keyword = data[\"keywords\"]\n",
    "        modified_keywords = delete_similar_words(keyword, sim_keywords_dic)\n",
    "        data[\"keywords\"] = modified_keywords\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    with open(DATAPATH + 'dblpv13_delete_similar_words.txt', 'a') as f:\n",
    "        f.write(json.dumps(data)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53ba060c6be498997ba07e186d74379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "キーワードの数:6272362, キーワードのない論文数:1171591,\n",
      " 期間が妥当である論文数2324357, 期間外の論文数1089509\n",
      "CPU times: user 1min 34s, sys: 8.69 s, total: 1min 42s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 2min30s needed\n",
    "keywords = {}\n",
    "count, count2, count3 = 0, 0, 0\n",
    "\n",
    "metadata = get_metadata(\"dblpv13_delete_similar_words.txt\")\n",
    "for paper in tqdm(metadata):\n",
    "    data = json.loads(paper)\n",
    "    try:\n",
    "        k = data.get('keywords')\n",
    "        y = data.get('year')\n",
    "        if len(k) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            if y >= START_YEAR and  END_YEAR >= y :\n",
    "                for i in k:\n",
    "                    i = i.lower().strip()\n",
    "                    if i == \"\":\n",
    "                        pass\n",
    "                    elif i not in keywords:\n",
    "                        keywords[i] = 1\n",
    "                    else:\n",
    "                        keywords[i] = keywords[i] + 1\n",
    "                count2 += 1\n",
    "            else:\n",
    "                count3 += 1\n",
    "    except Exception as e:\n",
    "        # keywordがないものも存在\n",
    "        count += 1\n",
    "        pass\n",
    "print(\"キーワードの数:{}, キーワードのない論文数:{},\\n 期間が妥当である論文数{}, 期間外の論文数{}\".format(len(keywords), count, count2, count3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0034c94dade74e7aa7184816151c86ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6272362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出現数が1000以上のキーワード数:2276\n",
      "CPU times: user 3.54 s, sys: 128 ms, total: 3.67 s\n",
      "Wall time: 3.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "important_keywords = []\n",
    "M = 1000\n",
    "for keyword in tqdm(keywords):\n",
    "    # keyword の出現回数が、Mを超えるとき\n",
    "    appear_count = keywords[keyword]\n",
    "    if appear_count >= M:\n",
    "        important_keywords.append(keyword)\n",
    "print(\"出現数が\" + str(M) + \"以上のキーワード数:{}\".format(len(important_keywords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_keywords.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in important_keywords:\n",
    "    if i in sim_keywords_dic:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATAPATH + \"DBLP/keywords_delete_similar_words.txt\", mode=\"a\") as f:\n",
    "    for i in important_keywords:\n",
    "        f.write(i + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5ac9074c40421cbf492f67471c5dc3e49846f397739518f542476e0deba3a6a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('trend')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
